# DE_Project_Olympic_Azure

In this simple data engineering pipeline project, I'm building a pipeline to ingest data from Git Hub into Azure Blob Storage.
I tried to become knowledgeable about Azure services while working on this project.
I therefore finished this project in two halves, the first of which included the pipeline for indivisually including various services.
And Auzre Synapse Analytics is used to finish the second one.
I gained knowledge of the many services, including App Registrations, Data Factory, Data Bricks, Azure Blob Storage, and Data Lake Storage.

Many lessons were learned while working on this project.
I gained knowledge regarding the purpose of manifest files in production usage. 

For this project, I made a stoarge account and used the Data Pipeline to copy the necessary data set from github to Azure DataFactory.
Pyspark code was used for transforming the data using DataBricks, and the data was subsequently dumped back into the storage container.

This project was quite beneficial in explaining the fundamentals of Azure.
